@misc{transformer,
    title = {Attention Is All You Need},
    author = {Ashish Vaswani and et al.},
    year = {2017}
}

@misc{glue,
    title = {GLUE: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding},
    author = {Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R.},
    year = {2019}
}

@misc{glue_human,
    title = {A Conservative Human Baseline Estimate for GLUE:People Still (Mostly) Beat Machines},
    author = {Nangia Nikita and Bowman Samuel R.},
    year = {2019}
}

@misc{bert,
    title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Devlin, Jacob and et al.},
    year = {2018}
}

@misc{gpt2,
    title = {Language Models are Unsupervised Multitask Learners},
    author = {Alec Radford and Jeffrey Wu and et al},
    year = {2019}
}