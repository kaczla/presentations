@misc{gpt2,
    title = {Language Models are Unsupervised Multitask Learners},
    author = {Alec Radford and Jeffrey Wu and et al},
    year = {2019}
}

@misc{bpe,
    title = {Neural Machine Translation of Rare Words with Subword Units},
    author = {Sennrich, Rico and Haddow, Barry and Birch, Alexandra},
    year = {2016},
}

@misc{transformer,
    title = {Attention Is All You Need},
    author = {Ashish Vaswani and et al.},
    year = {2017}
}

@misc{xception,
    author = {Fran√ßois Chollet},
    title = {Xception: Deep Learning with Depthwise Separable Convolutions},
    year = {2016}
}

@misc{gelu,
    title = {Gaussian Error Linear Units (GELUs)},
    author = {Dan Hendrycks and Kevin Gimpel},
    year = {2016}
}

@misc{bert,
    title = {BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding},
    author = {Devlin, Jacob and et al.},
    year = {2018}
}

@misc{evolved,
    author = {So, David and Liang, Chen and Le, Quoc},
    year = {2019},
    title = {The Evolved Transformer}
}

@misc{transformerxl,
    author = {Zihang Dai and Zhilin Yang and et al.},
    year = {2019},
    title = {Transformer-{XL}: Language Modeling with Longer-Term Dependency}
}

@misc{megatronlm,
    title = {Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism},
    author = {Mohammad Shoeybi and Mostofa Patwary and Raul Puri and et al.},
    year = {2019}
}

@misc{xlnet,
    author = {Yang, Zhilin and Dai, Zihang and et al.},
    title = {XLNet: Generalized Autoregressive Pretraining for Language Understanding},
    year = 2019
}

@misc{roberta,
    author = {Yinhan Liu and et al.},
    title = {RoBERTa: A Robustly Optimized BERT Pretraining Approach},
    year = 2019
}

@misc{structbert,
    title = {StructBERT: Incorporating Language Structures into Pre-training for Deep Language Understanding},
    author = {Wei Wang and et al.},
    year = {2019},
}

@misc{xlm,
    title = {Cross-lingual Language Model Pretraining},
    author = {Guillaume Lample, Alexis Conneau},
    year = {2019},
}

@misc{tidybert,
    title = {TinyBERT: Distilling BERT for Natural Language Understanding},
    author = {Xiaoqi Jiao and et al.},
    year = {2019},
}

@misc{ctrl,
    title = {CTRL - A Conditional Transformer Language Model for Controllable Generation},
    author = {Keskar, Nitish Shirish and et al.},
    year = {2019}
}

@misc{albert,
    title = {ALBERT: A Lite BERT for Self-supervised Learning of Language Representations},
    author = {Zhenzhong Lan and et al.},
    year = {2019}
}

@misc{t5,
    author = {Colin Raffel and et al.},
    title = {Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer},
    year = {2019}
}